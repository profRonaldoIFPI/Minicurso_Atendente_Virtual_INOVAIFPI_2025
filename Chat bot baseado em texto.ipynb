{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9_qMsPrgGUCW"
   },
   "source": [
    "# **Construindo um Chatbot com a API Gemini, Fundamentado em Documentos de texto**\n",
    "\n",
    "**Além do Conhecimento Geral para uma IA Fundamentada**\n",
    "A tarefa de criar um chatbot que responda a perguntas de usuários é uma aplicação comum de Grandes Modelos de Linguagem (LLMs). No entanto, um desafio significativo com LLMs de propósito geral, como o Gemini, é sua tendência a \"alucinar\".\n",
    "\n",
    "Para aplicações empresariais, acadêmicas ou especializadas, onde a precisão e a rastreabilidade são primordiais, as respostas do chatbot devem ser estritamente limitadas a um conjunto de documentos.\n",
    "\n",
    "A solução para este desafio é uma arquitetura conhecida como **Geração Aumentada por Recuperação (RAG)**. Em vez de simplesmente fazer uma pergunta ao LLM e esperar que ele \"saiba\" a resposta com base em seu vasto treinamento prévio, o RAG introduz um passo intermediário crucial.\n",
    "\n",
    "![](https://static.wixstatic.com/media/cfe500_0546c1c5b8b3430f90c039aaa4ab71e2~mv2.jpg/v1/fill/w_740,h_438,al_c,q_80,usm_0.66_1.00_0.01,enc_avif,quality_auto/cfe500_0546c1c5b8b3430f90c039aaa4ab71e2~mv2.jpg)\n",
    "\n",
    "1. **Prompt do Usuário**: Primeiro, o usuário insere um prompt com a pergunta (query) no sistema.\n",
    "\n",
    "2. **Busca por Informação**: A query é usada para consultar fontes de conhecimento (como documentos PDF, TXT, etc.) previamente indexadas.\n",
    "\n",
    "3. **Recuperação**: O sistema retorna ***trechos relevantes dos documentos*** que servirão como ***contexto aumentado***.\n",
    "\n",
    "4. **Preparação do Prompt**: O contexto recuperado é combinado com a query original, formando um novo prompt fundamentado.\n",
    "\n",
    "5. **Geração da Resposta**: O novo prompt é enviado ao LLM (como o Gemini), que gera uma resposta com base exclusivamente nas informações recuperadas.\n",
    "\n",
    "A arquitetura RAG pode ser definida como um pipeline de três estágios principais: **Indexação, Recuperação e Geração**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vOgUukZoJZbn"
   },
   "source": [
    "\n",
    "## 1. **Indexação**\n",
    "\n",
    "A Indexação na pratica é um processo em 3 etapas:\n",
    "\n",
    "1.1 **Ingestão**: Carregar e analisar os arquivos brutos PDF e TXT do seu corpus de conhecimento.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gUnmY57dLsVa"
   },
   "source": [
    "Instalação das dependencias:\n",
    "* google-generativeai: O SDK oficial do Google para interagir com a API Gemini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 6361,
     "status": "ok",
     "timestamp": 1751500941601,
     "user": {
      "displayName": "Ronaldo Pires Borges",
      "userId": "00032249735521270223"
     },
     "user_tz": 180
    },
    "id": "WIR64CKRk_uQ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -U -q google-generativeai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sW3teFxxMFhR"
   },
   "source": [
    "Chave da API do Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GOOGLE_API_KEY = \"Sua API Key aqui\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# no google colab use:\n",
    "from google.colab import userdata # em projetos reais use dotenv para \"esconder\" sua API KEY\n",
    "genai.configure(api_key=userdata.get('GOOGLE_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2301,
     "status": "ok",
     "timestamp": 1751491853195,
     "user": {
      "displayName": "Ronaldo Pires Borges",
      "userId": "00032249735521270223"
     },
     "user_tz": 180
    },
    "id": "kgC1RH8JMKv7"
   },
   "outputs": [],
   "source": [
    "# no vscode use:\n",
    "import google.generativeai as genai\n",
    "genai.configure(api_key=GOOGLE_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QqjTfgnwOE92"
   },
   "source": [
    " Importando texto de PDF\n",
    "\n",
    " Para este exemplo usaremos os arquivos PDF em `content`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "irBspatvlKXF"
   },
   "source": [
    "Instalação das dependencias:\n",
    "* pypdf: Biblioteca para extrair texto de arquivos PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 6974,
     "status": "ok",
     "timestamp": 1751500966079,
     "user": {
      "displayName": "Ronaldo Pires Borges",
      "userId": "00032249735521270223"
     },
     "user_tz": 180
    },
    "id": "D1PCL25klJmr"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -U -q pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2682,
     "status": "ok",
     "timestamp": 1751499015456,
     "user": {
      "displayName": "Ronaldo Pires Borges",
      "userId": "00032249735521270223"
     },
     "user_tz": 180
    },
    "id": "DYpjD5bnMENB"
   },
   "outputs": [],
   "source": [
    "# Ingestão de documentos (PDF/TXT) por diretório, com título por arquivo\n",
    "import os\n",
    "from pypdf import PdfReader\n",
    "\n",
    "# Caminho para os documentos (use relativo para portabilidade)\n",
    "dir_path = r\"\\content\"\n",
    "\n",
    "# Lista de documentos com título e texto\n",
    "documents = []  # cada item: {\"title\": str, \"text\": str}\n",
    "\n",
    "for fname in os.listdir(dir_path):\n",
    "    fpath = os.path.join(dir_path, fname)\n",
    "    if not os.path.isfile(fpath):\n",
    "        continue\n",
    "    ext = os.path.splitext(fname)[1].lower()\n",
    "    title = os.path.splitext(fname)[0]  # nome do arquivo sem extensão\n",
    "    if ext == \".pdf\":\n",
    "        reader = PdfReader(fpath)\n",
    "        pages = reader.pages\n",
    "        doc_text = ''.join((page.extract_text() or '') for page in pages)\n",
    "    elif ext == \".txt\":\n",
    "        with open(fpath, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "            doc_text = f.read()\n",
    "    else:\n",
    "        continue\n",
    "    if doc_text.strip():\n",
    "        documents.append({\"title\": title, \"text\": doc_text})\n",
    "\n",
    "# Mantém a variável `text` por compatibilidade com células seguintes\n",
    "text = \"\\n\\n\".join(doc[\"text\"] for doc in documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cyiflm-1JvTN"
   },
   "source": [
    "1.2 **Divisão (Chunking)**: Dividir estrategicamente o texto dos documentos em pedaços menores e gerenciáveis, conhecidos como \"chunks\".\n",
    "\n",
    "Esta etapa é fundamental por duas razões principais:\n",
    "\n",
    " - **Limites de Contexto do Modelo**: Os modelos de embedding e os LLMs têm um limite máximo de tokens que podem processar de uma só vez. Enviar um documento inteiro (100 páginas, por exemplo) excederia esse limite.\n",
    "\n",
    "- **Precisão da Recuperação**: Se você incorporar um documento inteiro em um único vetor, o vetor representará o significado médio de todo o documento. Quando um usuário faz uma pergunta específica, é improvável que a média de todo o documento seja a correspondência mais próxima. Chunks menores e mais focados permitem uma recuperação muito mais precisa e relevante.\n",
    "\n",
    "A escolha da estratégia de \"chunking\" é uma decisão de design importante. As estratégias comuns incluem:\n",
    "\n",
    "- **Tamanho Fixo (Fixed-Size)**: A abordagem mais simples, dividindo o texto em chunks de N caracteres ou tokens. Sua principal desvantagem é que pode cortar frases ou parágrafos no meio, quebrando o contexto semântico.\n",
    "- **Semântica (Semantic)**: Tenta dividir o texto em limites lógicos, como frases ou parágrafos.\n",
    "- **Recursiva (Recursive)**: Uma abordagem mais sofisticada que tenta dividir o texto usando uma hierarquia de separadores. Por exemplo, primeiro tenta dividir por parágrafos (\\n\\n). Se os chunks resultantes ainda forem muito grandes, ele os divide por frases, e assim por diante.\n",
    "\n",
    "Para a maioria dos documentos baseados em texto, a **Divisão Recursiva de Caracteres (Recursive Character Text Splitting)** oferece o melhor equilíbrio entre simplicidade e preservação do contexto semântico. Ela respeita a estrutura natural do documento, tentando manter os parágrafos e as frases intactos sempre que possível.\n",
    "\n",
    "Dois parâmetros chave nesta estratégia são `chunk_size` e `chunk_overlap`. `chunk_size` define o tamanho máximo de cada chunk. `chunk_overlap` especifica quantos caracteres do final de um chunk devem ser repetidos no início do próximo.\n",
    "\n",
    "![chunk overlap](https://cdn.analyticsvidhya.com/wp-content/uploads/2025/02/unnamed-1-67a0e0c9ca199-1.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NeZW4bdmlhAb"
   },
   "source": [
    "Instalação das dependencias:\n",
    "* langchain-text-splitters: Uma ferramenta útil para implementar estratégias de divisão de texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "executionInfo": {
     "elapsed": 9048,
     "status": "ok",
     "timestamp": 1751500992358,
     "user": {
      "displayName": "Ronaldo Pires Borges",
      "userId": "00032249735521270223"
     },
     "user_tz": 180
    },
    "id": "BRtdrvr5GMkS"
   },
   "outputs": [],
   "source": [
    "!pip install -U -q langchain-text-splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1751500999070,
     "user": {
      "displayName": "Ronaldo Pires Borges",
      "userId": "00032249735521270223"
     },
     "user_tz": 180
    },
    "id": "cvBCwdS-Gvrw"
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=400,\n",
    "    chunk_overlap=60,\n",
    "    length_function=len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"]\n",
    ")   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos estruturar os chunks adicionando metadados como, por exemplo, o título ou nome do documento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1751499029870,
     "user": {
      "displayName": "Ronaldo Pires Borges",
      "userId": "00032249735521270223"
     },
     "user_tz": 180
    },
    "id": "MVrLewx4G9gG"
   },
   "outputs": [],
   "source": [
    "chunks = []  # cada item: {\"text\": str, \"title\": str}\n",
    "for doc in documents:\n",
    "    for chunk_text in text_splitter.split_text(doc[\"text\"]):\n",
    "        chunks.append({\"text\": chunk_text, \"title\": doc[\"title\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1751499032668,
     "user": {
      "displayName": "Ronaldo Pires Borges",
      "userId": "00032249735521270223"
     },
     "user_tz": 180
    },
    "id": "lMzYEpg0RReu",
    "outputId": "b5279e8c-49b2-4593-b4ff-5ce091d0cf3c"
   },
   "outputs": [],
   "source": [
    "print(f\"Total de chunks criados: {len(chunks)}\")\n",
    "print(\"Exemplo título do primeiro chunk:\", chunks[0][\"title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 157
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1751499037253,
     "user": {
      "displayName": "Ronaldo Pires Borges",
      "userId": "00032249735521270223"
     },
     "user_tz": 180
    },
    "id": "18Ovz-7GG_6c",
    "outputId": "817fe315-1464-46cb-a553-aaee996af757"
   },
   "outputs": [],
   "source": [
    "chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 140
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1751499038828,
     "user": {
      "displayName": "Ronaldo Pires Borges",
      "userId": "00032249735521270223"
     },
     "user_tz": 180
    },
    "id": "b9GTDA3NHUSi",
    "outputId": "5f8c9195-0b14-40d7-b561-0e8c31825d69"
   },
   "outputs": [],
   "source": [
    "chunks[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tqrVK7lzJ0fn"
   },
   "source": [
    "1.3 **Embedding e Indexação**: Converter cada \"chunk\" de texto em uma representação numérica (um vetor de embedding) e armazenar esses vetores para busca rápida.\n",
    "\n",
    " - *Embedding:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "executionInfo": {
     "elapsed": 2668,
     "status": "ok",
     "timestamp": 1751496070654,
     "user": {
      "displayName": "Ronaldo Pires Borges",
      "userId": "00032249735521270223"
     },
     "user_tz": 180
    },
    "id": "R2mW6EfkJ24w",
    "outputId": "1cdc4d26-cebf-4f88-92cf-faff3d36cb5d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/embedding-001\n",
      "models/text-embedding-004\n",
      "models/gemini-embedding-exp-03-07\n",
      "models/gemini-embedding-exp\n",
      "models/gemini-embedding-001\n"
     ]
    }
   ],
   "source": [
    "models_names = []\n",
    "for model in genai.list_models():\n",
    "  if 'embedContent' in model.supported_generation_methods:\n",
    "    print(model.name)\n",
    "    models_names.append(model.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1751496378575,
     "user": {
      "displayName": "Ronaldo Pires Borges",
      "userId": "00032249735521270223"
     },
     "user_tz": 180
    },
    "id": "5VG72uGiUapP",
    "outputId": "a709453e-d8ae-4758-a256-6b652e28ea1d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'models/text-embedding-004'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_names[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "executionInfo": {
     "elapsed": 73992,
     "status": "ok",
     "timestamp": 1751499888395,
     "user": {
      "displayName": "Ronaldo Pires Borges",
      "userId": "00032249735521270223"
     },
     "user_tz": 180
    },
    "id": "OtmCYptzTxpL",
    "outputId": "86eabfde-ec97-4817-a5a6-206f8bda6a7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 750 ms\n",
      "Wall time: 2min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "embedded_chunks = []\n",
    "for chunk in chunks:\n",
    "    try:\n",
    "        result = genai.embed_content(\n",
    "            model=models_names[1],\n",
    "            content=chunk[\"text\"],\n",
    "            task_type=\"RETRIEVAL_DOCUMENT\"\n",
    "        )\n",
    "        chunk[\"embedding\"] = result['embedding']\n",
    "        embedded_chunks.append(chunk)\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao gerar embedding para o chunk: {chunk[:50]}... | Erro: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1751499979842,
     "user": {
      "displayName": "Ronaldo Pires Borges",
      "userId": "00032249735521270223"
     },
     "user_tz": 180
    },
    "id": "vOGmMjI1dhgL",
    "outputId": "fa696c98-747b-4730-cd9c-0a87ec2c2362"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'text': 'MINISTÉRIO DA JUSTIÇA\\nSecretaria Nacional do Consumidor\\nCÓDIGO DE PROTEÇÃO \\nE DEFESA DO CONSUMIDOR\\nNova edição revista, atualizada e ampliada com \\nos  Decretos nº 7.962, de 15 de março de 2013 \\ne  nº 7.963, de 15 de março de 2013\\nBrasília, 2013\\nBrasil\\n[Código de Proteção e Defesa do Consumidor(1990)]\\nCódigo de Defesa do Consumidor - Nova ed. rev., atu-\\nal. e ampl. com os Decretos nº 2.181, de 20 de março de \\n1997 e nº 7936, de 15 de março de 2013 - Brasília : Minis-\\ntério da Justiça, 2013\\n156 p. \\n1. Proteção ao consumidor - legislação - Brasil.\\nCDD 341.37Sumário\\nAPRESENTAÇÃO .............................................................11\\nLEI Nº 8.078, DE 11 DE SETEMBRO DE 1990. ...............13\\nTÍTULO I - Dos Direitos do Consumidor............................ 15\\nCAPÍTULO I - Disposições Gerais ..........................15\\nCAPÍTULO II - Da Política Nacional de Relações de \\nConsumo .................................................................16', 'title': 'Código de proteção e defesa do consumidor', 'embedding': [0.013315177, 0.00981638, 0.0025405376, -0.0016845971, 0.031020636, -0.019479865, -0.02919775, 0.049903505, 0.01467293, 0.057654604, 0.027611315, 0.005290196, 0.059683852, 0.03510994, 0.046956662, -0.056703556, 0.010681803, -0.0126700895, -0.15181898, -5.862989e-05, 0.026682915, -0.02937495, 0.033699613, -0.014340755, 0.028249713, -0.035387956, 0.011404938, -0.03371636, -0.07117023, -0.06054594, 0.004316932, 0.017804416, -0.02027936, -0.02789012, 0.04580269, 0.005337234, -0.0016835579, 0.008629925, 0.021942744, -0.034283675, 0.0034102628, 0.023233794, -0.025705438, 0.0010803425, -0.050690524, 0.0103929555, 0.0101372255, 0.014748458, -0.042948198, 0.022199959, 0.043204024, 0.06579859, -0.118696935, -0.00072118774, -0.035745587, 0.00119823, -0.0058541303, -0.09392681, -0.03220756, -0.019155597, 0.0519513, 0.040424127, -0.06791872, 0.000607745, 0.063260235, -0.028072307, 0.021945149, -0.077699594, -0.03716535, 0.004573305, 0.013975283, 0.030212779, -0.05423127, -0.0048413184, -0.022815775, -0.05405881, 0.100581065, -0.0128772035, -0.0054780915, 0.01168969, -0.04359279, 0.052680887, 0.015486912, -0.0017094347, 0.0008166371, -0.0030309064, -0.0017396065, -0.060276546, -0.012569639, -0.04719576, 0.01310155, 0.024505613, -0.009147749, -0.07610021, 0.05339441, -0.015890284, -0.14022632, -0.04994157, 0.035421684, -0.033724774, 0.028150609, 0.024198366, -0.032765776, -0.03966909, 0.043308806, -0.015944548, 0.038520426, -0.012371943, -0.019072058, 0.02845087, -0.017438205, -0.015863685, 0.065644816, -0.011374488, -0.00915011, -0.010454071, -0.012535137, 0.042828973, -0.047753744, 0.00043389638, -0.01008426, -0.03393758, -0.052680526, -0.007231931, 0.033133343, -0.02706263, -0.012584615, -0.0283637, -0.0041086082, -0.014759388, 0.043896038, -0.043295097, 0.009145486, 0.02107016, -0.04046074, 0.0051340186, 0.007776963, 0.00564912, -0.00065058406, -0.0076263226, -0.003058241, -0.074355625, -0.08139119, 0.026572203, -0.011310943, -0.026841491, 0.035037804, 0.04407876, -0.055571668, 0.007905067, -0.03670229, -0.0481299, 0.08872004, -0.044011932, -0.008011009, -0.06156124, 0.03859892, -0.032610185, -0.01184957, -0.011144321, 0.088182084, 0.019802857, 0.0070528556, -0.02064165, -0.08114069, 0.029668218, -0.018297162, -0.08219298, 0.023850707, 0.0056927204, 0.024018146, -0.04933101, 0.0646787, -0.15515375, 0.004930254, -0.005114471, 0.0041399444, 0.026016884, -0.024709972, 0.02607168, 0.085600674, 0.02141168, -0.03199762, -0.030980317, -0.0324411, -0.010700899, 0.024349151, 0.037863024, 0.070976734, 0.045781665, -0.019979928, 0.006119706, -0.015583815, 0.025840195, -0.03695086, -0.045833264, -0.017549561, -0.024216149, 0.031630147, -0.034125026, 0.024485774, 0.026384534, -0.011540307, -0.057053242, -0.026218403, 0.054791655, -0.045496926, -0.0032403476, -0.035354752, -0.0517471, 0.0045718066, 0.00027608871, -0.03596642, -0.055972695, 0.013402552, -0.03340544, 0.06614572, 0.009948082, -0.020466065, 0.022986798, -0.019816468, -0.013743689, 0.037914403, 0.06507697, -0.010465203, 0.026338639, -0.04251115, -0.013944964, 0.01628098, -0.019179594, -0.036211815, 0.03564047, 0.0059187817, -0.009133138, -0.053244833, -0.0034283905, 0.034539953, -0.06651305, -0.0055537815, 0.06374342, -0.002134529, 0.053156614, 0.08186316, 0.009717401, -0.0038451275, -0.03002589, 0.07367941, 0.03841713, -0.0072414856, -0.0667441, -0.030746622, 0.028561948, 0.02296156, 0.0055145794, -0.0140461, -0.01134475, 0.012670933, 0.017893147, 8.039454e-05, -0.031733435, 0.009234988, 0.012921133, -0.026342599, -0.01467122, -0.0044073346, -0.055335265, 0.0061203577, -0.0373887, 0.019896034, -0.027024038, -0.0048010615, -0.034372494, 0.011476048, 0.014972735, -0.0348229, -0.005660919, -0.004596462, 0.008127892, -0.019945882, -0.04943064, 0.11816172, 0.01124195, -0.008967803, 0.035817303, -0.01820212, -0.058155898, 0.076103866, 0.032679368, -0.023370512, 0.015630318, -0.0080955075, -0.011235578, 0.03019862, -0.005645733, 0.037350394, 0.0136566525, -0.00061150576, 0.026953664, 0.013614065, -0.041016717, 0.032969695, 0.021260038, -0.017406408, -0.038130816, 0.018080883, -0.051835444, 0.0015973846, -0.014099867, 0.015613439, -0.024760928, 0.02122962, 0.035876907, -0.026935868, -0.034431122, -0.007257222, 0.013546708, -0.19443503, 0.014529688, 0.038563624, -0.027238464, 0.017419407, 0.078016706, 0.028652614, -0.0018231991, 0.0138262855, -0.039038327, 0.041044444, -0.008831303, 0.006894725, -0.023806809, 0.010650973, 0.026661824, -0.0605189, -0.06956214, 0.00093974563, -0.026127648, -0.038806472, -0.008447428, 0.036814842, 0.030824674, 0.049896214, 0.020452801, 0.043877732, 0.03113638, -0.05791162, -0.028876137, 0.003537297, 0.0033435298, -0.046743564, -0.012639909, 0.029221289, 0.05377083, -0.002550312, -0.04601293, -0.0040977215, -0.047813736, 0.040129635, 0.023768788, 0.021137541, -0.054867912, 0.020768272, 0.015605047, -0.047649566, 0.040923342, 0.017497962, -0.013281146, -0.014920375, 0.0039259433, -0.0031656295, -0.021678, -0.013765403, 0.008867108, 0.0027049577, 0.04441437, 0.014814485, -0.048673064, -0.0153383715, 0.04200392, 0.00588845, 0.032484185, -0.045185886, -0.009354179, 0.04125896, -0.0157645, -0.01118367, 0.02404514, -0.060394283, 0.0119852545, -0.014325842, 0.02531361, -0.010183566, -0.027488887, -0.0009848707, 0.045791693, -0.0068724602, 0.022767013, -0.011777818, 0.03955515, 0.011743729, 0.027815785, -0.029579863, -0.050771967, 0.08896612, -0.007923926, 0.007048477, 0.017124683, 0.07522043, -0.017057125, 0.012604878, 0.041211765, -0.009977847, -0.05493028, -0.019482275, -0.01570439, -0.014538901, -0.018337814, 0.034469265, 0.019929556, 0.014709508, 0.020613458, 0.00033790484, 0.022273138, 0.06887562, 0.011122848, 0.044252574, -0.06646811, -0.018950427, -0.011904652, -0.033908565, -0.018896572, 0.041047838, 0.07223774, -0.02637734, 0.031853475, 0.03955941, 0.017865852, -0.0050069564, -0.035475098, -0.06372393, 0.009423577, -0.04307262, 0.0069579417, 0.028485835, -0.016512824, -0.06509171, 0.06041787, 0.04051602, -0.037595358, 0.005229862, -0.044820387, 0.009672909, -0.028247045, 0.02708388, 0.0023701547, -0.03008941, 0.022731865, 0.0061351415, 0.018338073, -0.04255688, 0.046127852, -0.06983273, -0.003957427, 0.008522104, 0.014854755, -0.04171338, -0.03901142, -0.044018272, -0.0008959607, -0.004877864, 0.013762934, 0.03413934, -0.008800223, 0.022816068, 0.0129232, -0.010781691, -0.01244221, -0.007553248, 0.003696174, -0.029481787, 0.044299174, 0.007430575, 0.021158302, 0.0046171066, -0.0075273234, 0.057789903, -0.05164105, -0.0083550215, 0.0011929941, -0.007973548, 0.037420515, -0.008043399, 0.009724555, 0.022755606, -0.018880235, -0.0032027964, 0.008722073, 0.016873958, -0.0023858678, -0.03728778, 0.03782909, 0.07782289, 0.0057477923, 0.020249836, -0.045952108, -0.016520465, 0.0144707365, -0.036071677, -0.032576464, 0.026065912, -0.0323112, -0.0048078042, 0.021621361, 0.0035543365, 0.016602745, 0.032754138, 0.0056863483, -0.054733384, -0.011528496, 0.029926168, 0.046241596, -0.0106625315, 0.012097956, -0.012524006, 0.012021711, -0.027689068, 0.040645506, -0.022284321, -0.010817009, 0.02518316, -0.03211834, -0.01548538, 0.0891817, 0.025853535, 0.030985923, -0.013164776, 0.046366785, 0.014966836, 0.00023016859, -0.022862941, -0.005142265, 0.0017527095, 0.009036262, 0.027640868, 0.007792517, 0.020575754, -0.044501808, -0.020429568, -0.028298791, -0.022651684, 0.11278313, 0.033537056, -0.051824708, -0.01708135, 0.04686987, 0.019823935, -0.016372534, 0.08480064, -0.00916203, -0.012136352, -0.0059058364, 0.035518948, -0.05515518, 0.037664767, 0.007902371, 0.047952536, 0.021603547, -0.018887235, 0.019489191, -0.024842842, 0.02351878, 0.022123957, 0.03436953, 0.04720484, -0.006695218, 0.045617808, -0.09647397, 0.0004560757, -0.011200854, 0.023285028, -0.053552296, -0.010081384, -0.00826329, 0.05350411, 0.022664482, 0.023978844, -0.031529896, 0.018340811, 0.048203554, -0.024051152, 0.057517663, 0.024918128, 0.008136292, 0.024313908, -0.039246805, 0.016591689, 0.0011216432, -0.06606623, 0.013558243, -0.04013649, 0.022743506, -0.019891748, 0.042398475, 0.041600868, -0.007107885, -0.03909812, -0.038846478, -0.0012724278, -0.041000515, -0.0056970436, -0.0070531596, -0.001355232, -0.013511896, 0.019781956, -0.026699482, 0.01667071, 0.023996513, -0.012654096, 0.019416217, 0.004438983, 0.026794631, -0.039666034, 0.009032035, 0.00522129, 0.004984827, -0.08556894, 0.020648543, 0.01019517, 0.03017689, 0.00025873096, 0.040300373, 0.026228292, -0.0030848675, 0.033602856, -0.017707212, -0.025888989, 0.007850688, -0.026590036, -0.0058865496, 0.0717014, -0.057863895, 0.049007248, 0.031660613, 0.09148317, 0.019330204, -0.0128187435, -0.0022203415, 0.0273523, -0.0014620994, 0.013152735, 0.0071062716, -0.024198307, -0.002885547, -0.025829954, 0.018915666, 0.0012281255, -0.0100485245, -0.005874441, 0.020025501, 0.02247256, 0.039085947, 0.03515875, -0.010780134, 0.01606298, 0.03622058, -0.015919076, -0.0042592217, -0.022818038, 0.008187592, 0.014582991, -0.05089545, 0.0051076035, 0.007241227, -0.043103836, -0.034390535, 0.004857824, 0.008547725, -0.027386632, -0.0350946, 0.05899585, 0.02739189, -0.044270426, 0.014131295, -0.0011954925, 0.009369133, -0.022103824, -0.018735537, 0.04283402, 0.03687077, -0.030924898, 0.079417415, 0.01652968, -0.05097055, -0.018731188, 0.02690975, -0.0038196757, 0.058923047, 0.0133746425, -0.018497918, -0.019744491, 0.0008991903, -0.06734342, -0.0112057915, -0.06491584, -0.019241104, -0.0051026107, -0.008293731, 0.047738448, 0.031056788, -0.0748756, 0.021884441, 0.001386127, 0.008949514, 0.07166103, 0.034996055, 0.017039137, 0.026301874, 0.03126435, 0.029522026, -0.001158669, 0.042382043, 0.0037630755, -0.03560982, -0.039449964, 0.037361223, 0.05532442, -0.0064390018, -0.07227536, 0.0179575, -0.052259587, 0.05588446, 0.062459514, -0.0030749566, -0.01302426, 0.012972989, 0.0548572, 0.0006878511, 0.016284717, -0.024161516, -0.004932062, -0.02828263, -0.014274978, 0.013166415, -0.036825337, 0.04668182, 0.007785084, 0.0034949898, 0.009883779, 0.0040037883, -0.00047956128, -0.032938175, -0.028580716, -0.020337883, 0.029175263, 0.045519162, 0.04136315, -0.05314178, -0.03777675, 0.0011633135, -0.007362421, 0.015481876, -0.001649282, 0.01726964, -0.0030530193, -0.015555352, -0.06669031, -0.024374356, 0.043830704, -0.037137497]}\n"
     ]
    }
   ],
   "source": [
    "print(embedded_chunks[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ix7keBLoinCN"
   },
   "source": [
    "- *Indexação:*\n",
    "\n",
    "Os embeddings precisam ser armazenados em um local que permita uma busca por similaridade extremamente rápida. Bancos de dados relacionais tradicionais não são projetados para este tipo de operação. Em vez disso, usamos **armazenamentos de vetores (vector stores)**. Seguem duas opções:\n",
    "1. **[ChromaDB](https://www.trychroma.com/)** é um banco de dados vetorial de código aberto, construído especificamente para aplicações de IA. Ele abstrai grande parte da complexidade. Com uma API simples, ele gerencia o armazenamento de embeddings, documentos e metadados em um único local.  \n",
    "\n",
    "2. **[FAISS (Facebook AI Similarity Search)](https://ai.meta.com/tools/faiss/)** não é um banco de dados, mas sim uma biblioteca de código aberto altamente otimizada para busca de similaridade em conjuntos densos de vetores.\n",
    "\n",
    "Para os propósitos deste guia, que visa construir um protótipo funcional, **ChromaDB** é a escolha recomendada devido à sua simplicidade e ciclo de desenvolvimento rápido."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eXe8O3A7lqYV"
   },
   "source": [
    "Instalação das dependencias:\n",
    "* ChromaDB: Um banco de dados vetorial de código aberto projetado para IA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "executionInfo": {
     "elapsed": 5985,
     "status": "ok",
     "timestamp": 1751501044167,
     "user": {
      "displayName": "Ronaldo Pires Borges",
      "userId": "00032249735521270223"
     },
     "user_tz": 180
    },
    "id": "5R8ol8tgimP3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install -U -q chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1751503832373,
     "user": {
      "displayName": "Ronaldo Pires Borges",
      "userId": "00032249735521270223"
     },
     "user_tz": 180
    },
    "id": "dlma2upEnw_F"
   },
   "outputs": [],
   "source": [
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1751503833977,
     "user": {
      "displayName": "Ronaldo Pires Borges",
      "userId": "00032249735521270223"
     },
     "user_tz": 180
    },
    "id": "tMchiFs0m60U"
   },
   "outputs": [],
   "source": [
    "DB_PATH = \"./chroma_db\"\n",
    "COLLECTION_NAME = \"document_chatbot\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1751503836037,
     "user": {
      "displayName": "Ronaldo Pires Borges",
      "userId": "00032249735521270223"
     },
     "user_tz": 180
    },
    "id": "TtBAqh4nmREC"
   },
   "outputs": [],
   "source": [
    "# Inicializa o cliente persistente\n",
    "client = chromadb.PersistentClient(path=DB_PATH)\n",
    "\n",
    "# Cria a coleção (db)\n",
    "collection = client.get_or_create_collection(name=COLLECTION_NAME)\n",
    "\n",
    "# Prepara os data for addition\n",
    "ids = [f\"chunk_{i}\" for i in range(len(embedded_chunks))]\n",
    "embeddings = [chunk[\"embedding\"] for chunk in embedded_chunks]\n",
    "documents = [chunk[\"text\"] for chunk in embedded_chunks]\n",
    "metadatas = [{\"title\": chunk[\"title\"]} for chunk in embedded_chunks]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ylzbtc8dypJg"
   },
   "source": [
    "Adiciona os dados à coleção (como um insert em uma tabela)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "executionInfo": {
     "elapsed": 279,
     "status": "ok",
     "timestamp": 1751503838710,
     "user": {
      "displayName": "Ronaldo Pires Borges",
      "userId": "00032249735521270223"
     },
     "user_tz": 180
    },
    "id": "5TrwYSgJm_Ym"
   },
   "outputs": [],
   "source": [
    "collection.upsert(\n",
    "    ids=ids,\n",
    "    documents=documents,\n",
    "    embeddings=embeddings,\n",
    "    metadatas=metadatas\n",
    ")\n",
    "# nomes das chaves e conteúdos não podem ser diferentes, o chromadb espera como está"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rhFN6odqJQBc"
   },
   "source": [
    "## 2. **Recuperação**\n",
    "\n",
    "Quando um usuário envia uma consulta, o primeiro passo é encontrar os \"chunks\" de texto mais relevantes em nossa base de conhecimento. Este processo de busca semântica tem duas etapas:\n",
    "\n",
    "1. **Incorporar a Consulta do Usuário**: A consulta do usuário (uma string de texto) deve ser convertida em um vetor de embedding usando o mesmo modelo que usamos para os documentos (text-embedding-004). Crucialmente, aqui usamos `task_type=\"RETRIEVAL_QUERY\"` para otimizar o vetor para a tarefa de busca.\n",
    "\n",
    "2. **Buscar por Similaridade**: O vetor da consulta é então usado para pesquisar no nosso armazenamento de vetores. A \"similaridade\" é tipicamente medida usando a **Similaridade de Cosseno (Cosine Similarity)**. Esta métrica calcula o cosseno do ângulo entre dois vetores. Um valor de `1` significa que os vetores apontam na mesma direção (semanticamente idênticos), `0` significa que são ortogonais (não relacionados), e `-1` significa que são opostos. Matematicamente, é calculado como o produto escalar dos vetores dividido pelo produto de suas magnitudes:\n",
    "$$\n",
    "S_C(A, B) = \\frac{A \\cdot B}{\\|A\\| \\|B\\|}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1751504972862,
     "user": {
      "displayName": "Ronaldo Pires Borges",
      "userId": "00032249735521270223"
     },
     "user_tz": 180
    },
    "id": "Gr2EA97N1OdD",
    "outputId": "279617c8-ee05-41eb-9ec3-9dd0b9264ad9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'models/text-embedding-004'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_names[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 42,
     "status": "ok",
     "timestamp": 1751505016125,
     "user": {
      "displayName": "Ronaldo Pires Borges",
      "userId": "00032249735521270223"
     },
     "user_tz": 180
    },
    "id": "dEuMQS2yJPeV"
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "def recupera_chunks_relevantes(query: str, n_results: int = 5) -> List[str]:\n",
    "    query_embedding_result = genai.embed_content(\n",
    "        model=models_names[1],\n",
    "        content=query,\n",
    "        task_type=\"RETRIEVAL_QUERY\"\n",
    "    )\n",
    "    query_embedding = query_embedding_result['embedding']\n",
    "\n",
    "    # Realiza a busca por similaridade na coleção\n",
    "    results = collection.query(\n",
    "        query_embeddings=[query_embedding],\n",
    "        n_results=n_results\n",
    "    )\n",
    "    return results['documents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 675,
     "status": "ok",
     "timestamp": 1751506948895,
     "user": {
      "displayName": "Ronaldo Pires Borges",
      "userId": "00032249735521270223"
     },
     "user_tz": 180
    },
    "id": "qIT5sfSo2a02",
    "outputId": "5d8bf85a-27a0-4b29-b51e-caf54a270275"
   },
   "outputs": [],
   "source": [
    "# Exemplo de uso:\n",
    "user_query = \"Aprovado\"\n",
    "relevant_chunks = recupera_chunks_relevantes(user_query)[0]\n",
    "print(f\"{len(relevant_chunks)} Chunk(s) relevante(s) encontrado(s):\")\n",
    "for i, chunk in enumerate(relevant_chunks):\n",
    "    print(f\"Chunk {i+1}:\\n{chunk}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iTldKynkJoqb"
   },
   "source": [
    "## 3. **Geração**\n",
    "\n",
    "Nesta etapa vamos usar os \"chunks\" recuperados como contexto para um modelo generativo.\n",
    "\n",
    "Esta é a etapa mais crítica para cumprir a restrição principal do usuário: garantir que o chatbot responda apenas com base nas informações fornecidas. Devemos construir um prompt que instrua o modelo Gemini a abandonar seu conhecimento geral e a se ater estritamente ao contexto que fornecemos. Isso é alcançado através de uma **engenharia de prompt**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1751506966015,
     "user": {
      "displayName": "Ronaldo Pires Borges",
      "userId": "00032249735521270223"
     },
     "user_tz": 180
    },
    "id": "iEfdgA0wJtAK"
   },
   "outputs": [],
   "source": [
    "def criar_prompt_rag(query: str, retrieved_chunks: List[str]) -> str:\n",
    "\n",
    "    # Persona/Instrução de Papel: Diga ao modelo qual é o seu papel\n",
    "    papel = \"Você é um assistente especialista. Sua tarefa é responder à pergunta do usuário com base exclusivamente no contexto fornecido.\"\n",
    "\n",
    "    # Instrução de Tarefa Clara: Diga ao modelo para basear sua resposta apenas no contexto.\n",
    "    terefa = \"Não utilize nenhum conhecimento externo ou treinamento prévio.\"\n",
    "\n",
    "    # Instrução de Fallback: Diga ao modelo o que fazer se a resposta não estiver no contexto\n",
    "    # fallback = \"Se a informação para responder à pergunta não estiver no contexto ou no histórico da conversa, você deve declarar:'Não consigo responder a esta pergunta com base nos documentos fornecidos.'\"\n",
    "    fallback = (\n",
    "        \"Se a informação para responder à pergunta não estiver no CONTEXTO dos documentos nem no HISTÓRICO RESUMIDO, responda exatamente: \"\n",
    "        \"'Não consigo responder a esta pergunta com base nos documentos fornecidos.' \"\n",
    "        \"Para perguntas sobre o próprio histórico da conversa (ex.: 'qual foi minha primeira pergunta?'), consulte o HISTÓRICO RESUMIDO ou o HISTÓRICO BRUTO se for mais preciso. \"\n",
    "        \"Não use conhecimento externo além desses.\"\n",
    "    )\n",
    "    # Contexto: Os \"chunks\" recuperados.\n",
    "    contexto = \"\\n\\n---\\n\\n\".join(retrieved_chunks)\n",
    "\n",
    "    # Pergunta: A pergunta original do usuário.\n",
    "    pergunta = query\n",
    "\n",
    "    prompt = f'{papel}\\n{terefa}\\n{fallback}\\nCONTEXTO:\\n---{contexto}\\n---\\nPERGUNTA:\\n{pergunta}\\nRESPOSTA:\\n'\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1751506984370,
     "user": {
      "displayName": "Ronaldo Pires Borges",
      "userId": "00032249735521270223"
     },
     "user_tz": 180
    },
    "id": "auO-nAg87aBD",
    "outputId": "4f2bfedf-0874-46bd-8b84-30c2e4c7dc4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Você é um assistente especialista. Sua tarefa é responder à pergunta do usuário com base exclusivamente no contexto fornecido.\n",
      "Não utilize nenhum conhecimento externo ou treinamento prévio.\n",
      "Se a informação para responder à pergunta não estiver no CONTEXTO dos documentos nem no HISTÓRICO RESUMIDO, responda exatamente: 'Não consigo responder a esta pergunta com base nos documentos fornecidos.' Para perguntas sobre o próprio histórico da conversa (ex.: 'qual foi minha primeira pergunta?'), consulte o HISTÓRICO RESUMIDO ou o HISTÓRICO BRUTO se for mais preciso. Não use conhecimento externo além desses.\n",
      "CONTEXTO:\n",
      "---das prestações pagas em benefício do credor que, em razão \n",
      "do inadimplemento, pleitear a resolução do contrato e a \n",
      "retomada do produto alienado.\n",
      "§ 1° (Vetado).\n",
      "§ 2º Nos contratos do sistema de consórcio de \n",
      "produtos duráveis, a compensação ou a restituição das \n",
      "parcelas quitadas, na forma deste artigo, terá descontada, \n",
      "além da vantagem econômica auferida com a fruição, os \n",
      "prejuízos que o desistente ou inadimplente causar ao grupo.\n",
      "§ 3° Os contratos de que trata o caput deste artigo \n",
      "serão expressos em moeda corrente nacional.\n",
      "SEÇÃO III \n",
      "Dos Contratos de Adesão\n",
      "Art. 54. Contrato de adesão é aquele cujas cláusulas \n",
      "tenham sido aprovadas pela autoridade competente ou \n",
      "estabelecidas unilateralmente pelo fornecedor de produtos \n",
      "ou serviços, sem que o consumidor possa discutir ou \n",
      "modificar substancialmente seu conteúdo. \n",
      "§ 1° A inserção de cláusula no formulário não \n",
      "desfigura a natureza de adesão do contrato.\n",
      "§ 2° Nos contratos de adesão admite-se cláusula\n",
      "\n",
      "---\n",
      "\n",
      "dez dias ou apresentar recurso.\n",
      "§ 3º Em caso de provimento do recurso, os valores \n",
      "recolhidos serão devolvidos ao recorrente na forma \n",
      "estabelecida pelo Conselho Gestor do Fundo.\n",
      "Art. 47. Quando a cominação prevista for a \n",
      "contrapropaganda, o processo poderá ser instruído com \n",
      "indicações técnico-publicitárias, das quais se intimará o \n",
      "autuado, obedecidas, na execução da respectiva decisão, \n",
      "as condições constantes do § 1º do art. 60 da Lei nº 8.078, \n",
      "de 1990.\n",
      "SEÇÃO VII\n",
      "Das Nulidades\n",
      "Art. 48. A inobservância de forma não acarretará a \n",
      "nulidade do ato, se não houver prejuízo para a defesa.\n",
      "Parágrafo único. A nulidade prejudica somente os \n",
      "atos posteriores ao ato declarado nulo e dele diretamente \n",
      "dependentes ou de que sejam conseqüência, cabendo à \n",
      "autoridade que a declarar indicar tais atos e determinar o \n",
      "adequado procedimento saneador, se for o caso.91\n",
      "SEÇÃO VIII\n",
      "Dos Recursos Administrativos\n",
      "Art. 49. Das decisões da autoridade competente do\n",
      "\n",
      "---\n",
      "\n",
      "os Ministérios Públicos da União, do Distrito Federal e dos \n",
      "Estados na defesa dos interesses e direitos de que cuida \n",
      "esta lei. (Vide Mensagem de veto) (Vide REsp 222582 /MG \n",
      "- STJ).\n",
      "§ 6° Os órgãos públicos legitimados poderão \n",
      "tomar dos interessados compromisso de ajustamento de \n",
      "sua conduta às exigências legais, mediante combinações, \n",
      "que terá eficácia de título executivo extrajudicial”. (Vide \n",
      "Mensagem de veto)  (Vide REsp 222582 /MG - STJ).\n",
      "Art. 114. O art. 15 da Lei n° 7.347, de 24 de julho de \n",
      "1985, passa a ter a seguinte redação:\n",
      "“Art. 15. Decorridos sessenta dias do trânsito em \n",
      "julgado da sentença condenatória, sem que a associação \n",
      "autora lhe promova a execução, deverá fazê-lo o Ministério \n",
      "Público, facultada igual iniciativa aos demais legitimados”.\n",
      "Art. 115. Suprima-se o caput do art. 17 da Lei n° \n",
      "7.347, de 24 de julho de 1985, passando o parágrafo único \n",
      "a constituir o caput, com a seguinte redação:\n",
      "“Art. 17. “Art. 17. Em caso de litigância de má-\n",
      "\n",
      "---\n",
      "\n",
      "IX - recusar a venda de bens ou a prestação de \n",
      "serviços, diretamente a quem se disponha a adquiri-los \n",
      "mediante pronto pagamento, ressalvados os casos de \n",
      "intermediação regulados em leis especiais; (Redação dada \n",
      "pela Lei nº 8.884, de 11.6.1994)\n",
      "X - elevar sem justa causa o preço de produtos ou \n",
      "serviços. (Incluído pela Lei nº 8.884, de 11.6.1994)\n",
      "XI -  Dispositivo  incluído pela MPV  nº 1.890-67, \n",
      "de 22.10.1999 , transformado em inciso  XIII, quando da \n",
      "converão na Lei nº 9.870, de 23.11.1999\n",
      "XII - deixar de estipular prazo para o cumprimento de \n",
      "sua obrigação ou deixar a fixação de seu termo inicial a seu \n",
      "exclusivo critério.(Incluído pela Lei nº 9.008, de 21.3.1995)\n",
      "XIII - aplicar fórmula ou índice de reajuste diverso do \n",
      "legal ou contratualmente estabelecido. (Incluído pela Lei nº \n",
      "9.870, de 23.11.1999)\n",
      "Parágrafo único. Os serviços prestados e os produtos \n",
      "remetidos ou entregues ao consumidor, na hipótese prevista \n",
      "no inciso III, equiparam-se às amostras grátis, inexistindo\n",
      "\n",
      "---\n",
      "\n",
      "apreendidos;\n",
      "d) as razões e os fundamentos da apreensão;\n",
      "e) o local onde o produto ficará armazenado;\n",
      "f) a quantidade de amostra colhida para análise;\n",
      "g) a identificação do agente autuante, sua \n",
      "assinatura, a indicação do seu cargo ou função e o número \n",
      "de sua matrícula;\n",
      "h) a assinatura do depositário;\n",
      "i) as proibições contidas no § 1º do art. 21 deste Decreto.\n",
      "Art. 36. Os Autos de Infração, de Apreensão e o \n",
      "Termo de Depósito serão lavrados pelo agente autuante que \n",
      "houver verificado a prática infrativa, preferencialmente no \n",
      "local onde foi comprovada a irregularidade.\n",
      "Art. 37. Os Autos de Infração, de Apreensão e o 87\n",
      "Termo de Depósito serão lavrados em impresso próprio, \n",
      "composto de três vias, numeradas tipograficamente.\n",
      "§ 1º Quando necessário, para comprovação de \n",
      "infração, os Autos serão acompanhados de laudo pericial.\n",
      "§ 2º Quando a verificação do defeito ou vício \n",
      "relativo à qualidade, oferta e apresentação de produtos não\n",
      "---\n",
      "PERGUNTA:\n",
      "Aprovado\n",
      "RESPOSTA:\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(criar_prompt_rag(\"Aprovado\", relevant_chunks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "suYe8MlD9cVg"
   },
   "source": [
    "**Resposta Final**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1751507450806,
     "user": {
      "displayName": "Ronaldo Pires Borges",
      "userId": "00032249735521270223"
     },
     "user_tz": 180
    },
    "id": "ESp_HRJT-nJt"
   },
   "outputs": [],
   "source": [
    "from google.generativeai.types import HarmCategory, HarmBlockThreshold # coleção de constantes (ENUM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 780
    },
    "executionInfo": {
     "elapsed": 2449,
     "status": "ok",
     "timestamp": 1751507204940,
     "user": {
      "displayName": "Ronaldo Pires Borges",
      "userId": "00032249735521270223"
     },
     "user_tz": 180
    },
    "id": "AjOL1NyB9uqU",
    "outputId": "b53b0740-3eaa-47e6-a0e9-d194335f8001"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - models/gemini-2.5-pro-preview-03-25\n",
      "1 - models/gemini-2.5-flash-preview-05-20\n",
      "2 - models/gemini-2.5-flash\n",
      "3 - models/gemini-2.5-flash-lite-preview-06-17\n",
      "4 - models/gemini-2.5-pro-preview-05-06\n",
      "5 - models/gemini-2.5-pro-preview-06-05\n",
      "6 - models/gemini-2.5-pro\n",
      "7 - models/gemini-2.0-flash-exp\n",
      "8 - models/gemini-2.0-flash\n",
      "9 - models/gemini-2.0-flash-001\n",
      "10 - models/gemini-2.0-flash-exp-image-generation\n",
      "11 - models/gemini-2.0-flash-lite-001\n",
      "12 - models/gemini-2.0-flash-lite\n",
      "13 - models/gemini-2.0-flash-preview-image-generation\n",
      "14 - models/gemini-2.0-flash-lite-preview-02-05\n",
      "15 - models/gemini-2.0-flash-lite-preview\n",
      "16 - models/gemini-2.0-pro-exp\n",
      "17 - models/gemini-2.0-pro-exp-02-05\n",
      "18 - models/gemini-exp-1206\n",
      "19 - models/gemini-2.0-flash-thinking-exp-01-21\n",
      "20 - models/gemini-2.0-flash-thinking-exp\n",
      "21 - models/gemini-2.0-flash-thinking-exp-1219\n",
      "22 - models/gemini-2.5-flash-preview-tts\n",
      "23 - models/gemini-2.5-pro-preview-tts\n",
      "24 - models/learnlm-2.0-flash-experimental\n",
      "25 - models/gemma-3-1b-it\n",
      "26 - models/gemma-3-4b-it\n",
      "27 - models/gemma-3-12b-it\n",
      "28 - models/gemma-3-27b-it\n",
      "29 - models/gemma-3n-e4b-it\n",
      "30 - models/gemma-3n-e2b-it\n",
      "31 - models/gemini-flash-latest\n",
      "32 - models/gemini-flash-lite-latest\n",
      "33 - models/gemini-pro-latest\n",
      "34 - models/gemini-2.5-flash-lite\n",
      "35 - models/gemini-2.5-flash-image-preview\n",
      "36 - models/gemini-2.5-flash-image\n",
      "37 - models/gemini-2.5-flash-preview-09-2025\n",
      "38 - models/gemini-2.5-flash-lite-preview-09-2025\n",
      "39 - models/gemini-robotics-er-1.5-preview\n",
      "40 - models/gemini-2.5-computer-use-preview-10-2025\n"
     ]
    }
   ],
   "source": [
    "model_list = []\n",
    "for i,  model in enumerate(genai.list_models()):\n",
    "  if 'generateContent' in model.supported_generation_methods: #lista modelos generativos\n",
    "    print(f'{i-1} - {model.name}')\n",
    "    model_list.append(model.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1751507455041,
     "user": {
      "displayName": "Ronaldo Pires Borges",
      "userId": "00032249735521270223"
     },
     "user_tz": 180
    },
    "id": "hpG8T1WT-iS7"
   },
   "outputs": [],
   "source": [
    "generation_config = {\n",
    "    \"candidate_count\": 1,\n",
    "    \"temperature\": 1\n",
    "}\n",
    "safety_settings = { \n",
    "    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
    "    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
    "    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
    "    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1751507780095,
     "user": {
      "displayName": "Ronaldo Pires Borges",
      "userId": "00032249735521270223"
     },
     "user_tz": 180
    },
    "id": "MnoOGCrl-ySC"
   },
   "outputs": [],
   "source": [
    "# model = genai.GenerativeModel(\n",
    "#     model_name=model_list[8],\n",
    "#     generation_config=generation_config,\n",
    "#     safety_settings=safety_settings # opcional, mas recomendado\n",
    "#     )\n",
    "model = genai.GenerativeModel(\n",
    "    model_name=model_list[8],\n",
    "    generation_config=generation_config\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "executionInfo": {
     "elapsed": 16900,
     "status": "ok",
     "timestamp": 1751507962364,
     "user": {
      "displayName": "Ronaldo Pires Borges",
      "userId": "00032249735521270223"
     },
     "user_tz": 180
    },
    "id": "o9K9zBXg_Q2Q",
    "outputId": "c5559c48-3b19-43a0-c604-81752531932f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O horário de funcionamento é de segunda a sexta das 7h às 19h e sábado das 7h às 12h. Domingos e feriados a clínica está fechada.\n"
     ]
    }
   ],
   "source": [
    "query = input(\"Prompt do usuário: \")\n",
    "print(\"Usuário: \", query)\n",
    "query_chunks = recupera_chunks_relevantes(query)[0]\n",
    "prompt_RAG = criar_prompt_rag(query, query_chunks)\n",
    "response = model.generate_content(prompt_RAG)\n",
    "print(f'Modelo: {response.text}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IBJsjmAvBuM0"
   },
   "source": [
    "**Chat continuo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 280
    },
    "executionInfo": {
     "elapsed": 70475,
     "status": "ok",
     "timestamp": 1751508563327,
     "user": {
      "displayName": "Ronaldo Pires Borges",
      "userId": "00032249735521270223"
     },
     "user_tz": 180
    },
    "id": "sYFxuglAB_3p",
    "outputId": "5fb8d829-fd77-40ee-c93a-1432a08d3a81"
   },
   "outputs": [],
   "source": [
    "chat = model.start_chat(history=[])\n",
    "\n",
    "query = \"\"\n",
    "while query != \"fim\":\n",
    "  query = input()\n",
    "  print(\"Usuário: \", query)\n",
    "  query_chunks = recupera_chunks_relevantes(query)[0]\n",
    "  prompt_RAG = criar_prompt_rag(query, query_chunks)\n",
    "  response = chat.send_message(prompt_RAG)\n",
    "  print(f'Chatbot: {response.text}')\n",
    "  "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyP9nUknTdWqRcav1qfneVPz",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
